EXECUTION TIME: 2025-05-14 19:01:59
[COMMENT] first attempt
EXECUTION TIME: 2025-05-14 19:03:31
[COMMENT] first attempt
EXECUTION TIME: 2025-05-14 19:08:22
[COMMENT] first attempt
EXECUTION TIME: 2025-05-14 19:08:37
[COMMENT] first attempt
EXECUTION TIME: 2025-05-14 19:09:08
[COMMENT] first attempt
EXECUTION TIME: 2025-05-14 19:09:39
[COMMENT] first attempt
EXECUTION TIME: 2025-05-14 19:12:11
[COMMENT] first attempt
EXECUTION TIME: 2025-05-14 19:13:12
[COMMENT] first attempt
Running with: /home/tommaso/anaconda3/bin/python3 Transformers 4.51.3
EXECUTION TIME: 2025-05-14 19:13:57
[COMMENT] first attempt
Running with: /home/tommaso/anaconda3/bin/python3 Transformers 4.51.3
EXECUTION TIME: 2025-05-14 19:14:33
[COMMENT] first attempt
Running with: /home/tommaso/anaconda3/bin/python3 Transformers 4.51.3
EXECUTION TIME: 2025-05-14 19:18:34
[COMMENT] first attempt
Running with: /home/tommaso/anaconda3/bin/python3 Transformers 4.51.3
EXECUTION TIME: 2025-05-14 19:19:29
[COMMENT] first attempt
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00028071428571428567, 'epoch': 0.71}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 9.3892, 'eval_samples_per_second': 2.663, 'eval_steps_per_second': 0.746, 'epoch': 1.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0002592857142857143, 'epoch': 1.43}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 8.4627, 'eval_samples_per_second': 2.954, 'eval_steps_per_second': 0.827, 'epoch': 2.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00023785714285714282, 'epoch': 2.14}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0002164285714285714, 'epoch': 2.86}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 8.9813, 'eval_samples_per_second': 2.784, 'eval_steps_per_second': 0.779, 'epoch': 3.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.000195, 'epoch': 3.57}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 8.8875, 'eval_samples_per_second': 2.813, 'eval_steps_per_second': 0.788, 'epoch': 4.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00017357142857142859, 'epoch': 4.29}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00015214285714285712, 'epoch': 5.0}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 10.4512, 'eval_samples_per_second': 2.392, 'eval_steps_per_second': 0.67, 'epoch': 5.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0001307142857142857, 'epoch': 5.71}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 9.4678, 'eval_samples_per_second': 2.641, 'eval_steps_per_second': 0.739, 'epoch': 6.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00010928571428571427, 'epoch': 6.43}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 9.9043, 'eval_samples_per_second': 2.524, 'eval_steps_per_second': 0.707, 'epoch': 7.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 8.785714285714286e-05, 'epoch': 7.14}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 6.642857142857142e-05, 'epoch': 7.86}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 9.6609, 'eval_samples_per_second': 2.588, 'eval_steps_per_second': 0.725, 'epoch': 8.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 4.4999999999999996e-05, 'epoch': 8.57}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 9.3467, 'eval_samples_per_second': 2.675, 'eval_steps_per_second': 0.749, 'epoch': 9.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 2.3571428571428568e-05, 'epoch': 9.29}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 2.1428571428571427e-06, 'epoch': 10.0}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 9.2165, 'eval_samples_per_second': 2.713, 'eval_steps_per_second': 0.76, 'epoch': 10.0}
{'train_runtime': 890.6192, 'train_samples_per_second': 0.629, 'train_steps_per_second': 0.157, 'train_loss': 0.0, 'epoch': 10.0}
[CHECKPOINT] Best model @ artifacts/checkpoints
--- FINAL VALIDATION METRICS ---
accuracy  : 0.52
precision : 0.0
recall    : 0.0
f1        : 0.0
roc_auc   : nan
Confusion-matrix and ROC curve saved to artifacts/plots/
EXECUTION TIME: 2025-05-14 19:45:04
[COMMENT] backprop attempt
EXECUTION TIME: 2025-05-14 20:01:35
[COMMENT] backprop attempt
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.357142857142859e-06, 'epoch': 0.71}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 9.3135, 'eval_samples_per_second': 2.684, 'eval_steps_per_second': 0.752, 'epoch': 1.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 8.642857142857144e-06, 'epoch': 1.43}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 9.6849, 'eval_samples_per_second': 2.581, 'eval_steps_per_second': 0.723, 'epoch': 2.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.928571428571429e-06, 'epoch': 2.14}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.2142857142857145e-06, 'epoch': 2.86}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 11.0015, 'eval_samples_per_second': 2.272, 'eval_steps_per_second': 0.636, 'epoch': 3.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 6.5000000000000004e-06, 'epoch': 3.57}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 8.621, 'eval_samples_per_second': 2.9, 'eval_steps_per_second': 0.812, 'epoch': 4.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5.785714285714286e-06, 'epoch': 4.29}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5.071428571428571e-06, 'epoch': 5.0}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 8.7778, 'eval_samples_per_second': 2.848, 'eval_steps_per_second': 0.797, 'epoch': 5.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 4.357142857142857e-06, 'epoch': 5.71}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 10.7406, 'eval_samples_per_second': 2.328, 'eval_steps_per_second': 0.652, 'epoch': 6.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 3.642857142857143e-06, 'epoch': 6.43}
EXECUTION TIME: 2025-05-15 11:48:19
[COMMENT] trying to get some loss values
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.357142857142859e-06, 'epoch': 0.71}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 4.8586, 'eval_samples_per_second': 5.146, 'eval_steps_per_second': 1.441, 'epoch': 1.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 8.642857142857144e-06, 'epoch': 1.43}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 5.3076, 'eval_samples_per_second': 4.71, 'eval_steps_per_second': 1.319, 'epoch': 2.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.928571428571429e-06, 'epoch': 2.14}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.2142857142857145e-06, 'epoch': 2.86}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 6.9204, 'eval_samples_per_second': 3.612, 'eval_steps_per_second': 1.011, 'epoch': 3.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 6.5000000000000004e-06, 'epoch': 3.57}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 6.7649, 'eval_samples_per_second': 3.696, 'eval_steps_per_second': 1.035, 'epoch': 4.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5.785714285714286e-06, 'epoch': 4.29}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5.071428571428571e-06, 'epoch': 5.0}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 9.4352, 'eval_samples_per_second': 2.65, 'eval_steps_per_second': 0.742, 'epoch': 5.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 4.357142857142857e-06, 'epoch': 5.71}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 5.3228, 'eval_samples_per_second': 4.697, 'eval_steps_per_second': 1.315, 'epoch': 6.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 3.642857142857143e-06, 'epoch': 6.43}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 7.6094, 'eval_samples_per_second': 3.285, 'eval_steps_per_second': 0.92, 'epoch': 7.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 2.928571428571429e-06, 'epoch': 7.14}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 2.2142857142857146e-06, 'epoch': 7.86}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 10.0563, 'eval_samples_per_second': 2.486, 'eval_steps_per_second': 0.696, 'epoch': 8.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 1.5e-06, 'epoch': 8.57}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 8.0934, 'eval_samples_per_second': 3.089, 'eval_steps_per_second': 0.865, 'epoch': 9.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.857142857142857e-07, 'epoch': 9.29}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.142857142857144e-08, 'epoch': 10.0}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 7.1981, 'eval_samples_per_second': 3.473, 'eval_steps_per_second': 0.972, 'epoch': 10.0}
{'train_runtime': 555.7809, 'train_samples_per_second': 1.008, 'train_steps_per_second': 0.252, 'train_loss': 0.0, 'epoch': 10.0}
[CHECKPOINT] Best model @ artifacts/checkpoints
--- FINAL VALIDATION METRICS ---
accuracy  : 0.52
precision : 0.0
recall    : 0.0
f1        : 0.0
roc_auc   : nan
Confusion-matrix and ROC curve saved to artifacts/plots/
EXECUTION TIME: 2025-05-15 11:59:13
[COMMENT] trying to get some loss values
input_values torch.Size([2, 64000]) torch.float32 -8.738493919372559 10.033743858337402
labels torch.Size([2]) torch.int64 1 1
EXECUTION TIME: 2025-05-15 12:00:39
[COMMENT] trying to get some loss values
input_values torch.Size([2, 64000]) torch.float32 -8.262988090515137 7.242766380310059
labels torch.Size([2]) torch.int64 1 1
EXECUTION TIME: 2025-05-15 12:03:42
[COMMENT] trying to get some loss values
input_values torch.Size([2, 64000]) torch.float32 -8.262988090515137 7.242766380310059
attention_mask torch.Size([2, 64000]) torch.int32 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6896)
any NaN? False
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.357142857142859e-06, 'epoch': 0.71}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 7.3637, 'eval_samples_per_second': 3.395, 'eval_steps_per_second': 0.951, 'epoch': 1.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 8.642857142857144e-06, 'epoch': 1.43}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 4.9481, 'eval_samples_per_second': 5.052, 'eval_steps_per_second': 1.415, 'epoch': 2.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.928571428571429e-06, 'epoch': 2.14}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.2142857142857145e-06, 'epoch': 2.86}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 6.2895, 'eval_samples_per_second': 3.975, 'eval_steps_per_second': 1.113, 'epoch': 3.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 6.5000000000000004e-06, 'epoch': 3.57}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 5.8728, 'eval_samples_per_second': 4.257, 'eval_steps_per_second': 1.192, 'epoch': 4.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5.785714285714286e-06, 'epoch': 4.29}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5.071428571428571e-06, 'epoch': 5.0}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 5.652, 'eval_samples_per_second': 4.423, 'eval_steps_per_second': 1.238, 'epoch': 5.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 4.357142857142857e-06, 'epoch': 5.71}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 10.3425, 'eval_samples_per_second': 2.417, 'eval_steps_per_second': 0.677, 'epoch': 6.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 3.642857142857143e-06, 'epoch': 6.43}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 7.704, 'eval_samples_per_second': 3.245, 'eval_steps_per_second': 0.909, 'epoch': 7.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 2.928571428571429e-06, 'epoch': 7.14}
EXECUTION TIME: 2025-05-15 12:10:49
[COMMENT] probe after grad clip + no norm
input_values torch.Size([2, 64000]) torch.float32 -1.0003697872161865 0.8769901990890503
attention_mask torch.Size([2, 64000]) torch.int32 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6858)
any NaN? False
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 3.5714285714285718e-06, 'epoch': 0.71}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 4.9155, 'eval_samples_per_second': 5.086, 'eval_steps_per_second': 1.424, 'epoch': 1.0}
{'train_runtime': 45.9074, 'train_samples_per_second': 1.22, 'train_steps_per_second': 0.305, 'train_loss': 0.0, 'epoch': 1.0}
[CHECKPOINT] Best model @ artifacts/checkpoints
--- FINAL VALIDATION METRICS ---
accuracy  : 0.52
precision : 0.0
recall    : 0.0
f1        : 0.0
roc_auc   : nan
Confusion-matrix and ROC curve saved to artifacts/plots/
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
EXECUTION TIME: 2025-05-15 12:22:45
[COMMENT] probe after grad clip + no norm
input_values torch.Size([2, 64000]) torch.float32 -1.0003697872161865 0.8769901990890503
attention_mask torch.Size([2, 64000]) torch.int32 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6858)
any NaN? False
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 3.5714285714285718e-06, 'epoch': 0.71}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 5.0423, 'eval_samples_per_second': 4.958, 'eval_steps_per_second': 1.388, 'epoch': 1.0}
{'train_runtime': 42.1129, 'train_samples_per_second': 1.33, 'train_steps_per_second': 0.332, 'train_loss': 0.0, 'epoch': 1.0}
[CHECKPOINT] Best model @ artifacts/checkpoints
--- FINAL VALIDATION METRICS ---
accuracy  : 0.52
precision : 0.0
recall    : 0.0
f1        : 0.0
roc_auc   : nan
Confusion-matrix and ROC curve saved to artifacts/plots/
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
EXECUTION TIME: 2025-05-15 12:32:23
[COMMENT] head only, lr5e-4
input_values torch.Size([2, 64000]) torch.float32 -1.0003697872161865 0.8769901990890503
attention_mask torch.Size([2, 64000]) torch.int32 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6858)
any NaN? False
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
EXECUTION TIME: 2025-05-15 12:33:36
[COMMENT] head only, lr5e-4
input_values torch.Size([2, 64000]) torch.float32 -1.0003697872161865 0.8769901990890503
attention_mask torch.Size([2, 64000]) torch.int32 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6858)
any NaN? False
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0003928571428571429, 'epoch': 0.71}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 4.6894, 'eval_samples_per_second': 5.331, 'eval_steps_per_second': 1.493, 'epoch': 1.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.0002738095238095238, 'epoch': 1.43}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 4.8364, 'eval_samples_per_second': 5.169, 'eval_steps_per_second': 1.447, 'epoch': 2.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 0.00015476190476190478, 'epoch': 2.14}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 3.571428571428571e-05, 'epoch': 2.86}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 9.233, 'eval_samples_per_second': 2.708, 'eval_steps_per_second': 0.758, 'epoch': 3.0}
{'train_runtime': 118.5958, 'train_samples_per_second': 1.417, 'train_steps_per_second': 0.354, 'train_loss': 0.0, 'epoch': 3.0}
[CHECKPOINT] Best model @ artifacts/checkpoints
--- FINAL VALIDATION METRICS ---
accuracy  : 0.52
precision : 0.0
recall    : 0.0
f1        : 0.0
roc_auc   : nan
Confusion-matrix and ROC curve saved to artifacts/plots/
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
EXECUTION TIME: 2025-05-15 12:36:37
[COMMENT] head only, lr5e-4
input_values torch.Size([2, 64000]) torch.float32 -1.0003697872161865 0.8769901990890503
attention_mask torch.Size([2, 64000]) torch.int32 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6858)
any NaN? False
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.857142857142858e-06, 'epoch': 0.71}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 5.8417, 'eval_samples_per_second': 4.28, 'eval_steps_per_second': 1.198, 'epoch': 1.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5.476190476190477e-06, 'epoch': 1.43}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 6.055, 'eval_samples_per_second': 4.129, 'eval_steps_per_second': 1.156, 'epoch': 2.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 3.0952380952380957e-06, 'epoch': 2.14}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.142857142857143e-07, 'epoch': 2.86}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 5.0423, 'eval_samples_per_second': 4.958, 'eval_steps_per_second': 1.388, 'epoch': 3.0}
{'train_runtime': 123.8759, 'train_samples_per_second': 1.356, 'train_steps_per_second': 0.339, 'train_loss': 0.0, 'epoch': 3.0}
[CHECKPOINT] Best model @ artifacts/checkpoints
--- FINAL VALIDATION METRICS ---
accuracy  : 0.52
precision : 0.0
recall    : 0.0
f1        : 0.0
roc_auc   : nan
Confusion-matrix and ROC curve saved to artifacts/plots/
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
EXECUTION TIME: 2025-05-15 13:19:45
[COMMENT] explicit mask + raw pcm
input_values torch.Size([2, 64000]) torch.float32 -1.1361515522003174 0.9960044622421265
attention_mask torch.Size([2, 64000]) torch.int64 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6869)
any NaN? False
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.857142857142858e-06, 'epoch': 0.71}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 5.0168, 'eval_samples_per_second': 4.983, 'eval_steps_per_second': 1.395, 'epoch': 1.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5.476190476190477e-06, 'epoch': 1.43}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 5.6981, 'eval_samples_per_second': 4.387, 'eval_steps_per_second': 1.228, 'epoch': 2.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 3.0952380952380957e-06, 'epoch': 2.14}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.142857142857143e-07, 'epoch': 2.86}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 5.3246, 'eval_samples_per_second': 4.695, 'eval_steps_per_second': 1.315, 'epoch': 3.0}
{'train_runtime': 114.8485, 'train_samples_per_second': 1.463, 'train_steps_per_second': 0.366, 'train_loss': 0.0, 'epoch': 3.0}
[CHECKPOINT] Best model @ artifacts/checkpoints
--- FINAL VALIDATION METRICS ---
accuracy  : 0.52
precision : 0.0
recall    : 0.0
f1        : 0.0
roc_auc   : nan
Confusion-matrix and ROC curve saved to artifacts/plots/
[INFO] Training complete.


🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
EXECUTION TIME: 2025-05-15 14:17:48
[COMMENT] new approach
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
EXECUTION TIME: 2025-05-15 14:18:58
[COMMENT] new approach
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
EXECUTION TIME: 2025-05-15 14:19:09
[COMMENT] new approach
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
EXECUTION TIME: 2025-05-15 14:35:36
[COMMENT] other tests
input_values torch.Size([2, 64000]) torch.float32 -1.1664526462554932 1.035493016242981
attention_mask torch.Size([2, 64000]) torch.int64 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6839)
any NaN? False
{'loss': 0.6931, 'grad_norm': 0.35788485407829285, 'learning_rate': 7.857142857142858e-06, 'epoch': 0.71}
{'eval_loss': 0.6907185912132263, 'eval_accuracy': 0.6, 'eval_precision': 0.625, 'eval_recall': 0.4166666666666667, 'eval_f1': 0.5, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 4.9592, 'eval_samples_per_second': 5.041, 'eval_steps_per_second': 1.412, 'epoch': 1.0}
{'loss': 0.6952, 'grad_norm': 4.867040157318115, 'learning_rate': 5.476190476190477e-06, 'epoch': 1.43}
{'eval_loss': 0.6907312870025635, 'eval_accuracy': 0.64, 'eval_precision': 0.6666666666666666, 'eval_recall': 0.5, 'eval_f1': 0.5714285714285714, 'eval_roc_auc': 0.673076923076923, 'eval_runtime': 4.9102, 'eval_samples_per_second': 5.091, 'eval_steps_per_second': 1.426, 'epoch': 2.0}
{'loss': 0.6929, 'grad_norm': 1.7819777727127075, 'learning_rate': 3.0952380952380957e-06, 'epoch': 2.14}
{'loss': 0.693, 'grad_norm': 0.21003323793411255, 'learning_rate': 7.142857142857143e-07, 'epoch': 2.86}
{'eval_loss': 0.6907414197921753, 'eval_accuracy': 0.68, 'eval_precision': 0.7, 'eval_recall': 0.5833333333333334, 'eval_f1': 0.6363636363636364, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 5.61, 'eval_samples_per_second': 4.456, 'eval_steps_per_second': 1.248, 'epoch': 3.0}
{'train_runtime': 103.9041, 'train_samples_per_second': 1.617, 'train_steps_per_second': 0.404, 'train_loss': 0.6932725395475116, 'epoch': 3.0}
[CHECKPOINT] Best model @ artifacts/checkpoints/checkpoint-28
--- FINAL VALIDATION METRICS ---
accuracy  : 0.64
precision : 0.6666666666666666
recall    : 0.5
f1        : 0.5714285714285714
roc_auc   : 0.673076923076923
Confusion-matrix and ROC curve saved to artifacts/plots/
[INFO] Training complete.


EXECUTION TIME: 2025-05-15 14:57:59
[COMMENT] FIRST WORKING RUN
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 64000]) torch.float32 -1.1664526462554932 1.035493016242981
attention_mask torch.Size([2, 64000]) torch.int64 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6839)
any NaN? False
{'loss': 0.6931, 'grad_norm': 0.3574638068675995, 'learning_rate': 9.357142857142859e-06, 'epoch': 0.71}
{'eval_loss': 0.6907294988632202, 'eval_accuracy': 0.6, 'eval_precision': 0.625, 'eval_recall': 0.4166666666666667, 'eval_f1': 0.5, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 6.343, 'eval_samples_per_second': 3.941, 'eval_steps_per_second': 1.104, 'epoch': 1.0}
{'loss': 0.6953, 'grad_norm': 4.869986057281494, 'learning_rate': 8.642857142857144e-06, 'epoch': 1.43}
{'eval_loss': 0.6907522678375244, 'eval_accuracy': 0.68, 'eval_precision': 0.7, 'eval_recall': 0.5833333333333334, 'eval_f1': 0.6363636363636364, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 5.6658, 'eval_samples_per_second': 4.412, 'eval_steps_per_second': 1.235, 'epoch': 2.0}
{'loss': 0.693, 'grad_norm': 1.7849892377853394, 'learning_rate': 7.928571428571429e-06, 'epoch': 2.14}
{'loss': 0.693, 'grad_norm': 0.20990872383117676, 'learning_rate': 7.2142857142857145e-06, 'epoch': 2.86}
{'eval_loss': 0.6907914876937866, 'eval_accuracy': 0.64, 'eval_precision': 0.6363636363636364, 'eval_recall': 0.5833333333333334, 'eval_f1': 0.6086956521739131, 'eval_roc_auc': 0.6538461538461539, 'eval_runtime': 8.2724, 'eval_samples_per_second': 3.022, 'eval_steps_per_second': 0.846, 'epoch': 3.0}
{'loss': 0.689, 'grad_norm': 0.9054084420204163, 'learning_rate': 6.5000000000000004e-06, 'epoch': 3.57}
{'eval_loss': 0.6907639503479004, 'eval_accuracy': 0.56, 'eval_precision': 0.5714285714285714, 'eval_recall': 0.3333333333333333, 'eval_f1': 0.42105263157894735, 'eval_roc_auc': 0.6538461538461539, 'eval_runtime': 5.7726, 'eval_samples_per_second': 4.331, 'eval_steps_per_second': 1.213, 'epoch': 4.0}
{'loss': 0.6928, 'grad_norm': 0.9806934595108032, 'learning_rate': 5.785714285714286e-06, 'epoch': 4.29}
{'loss': 0.6915, 'grad_norm': 2.8866724967956543, 'learning_rate': 5.071428571428571e-06, 'epoch': 5.0}
{'eval_loss': 0.6908227801322937, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6217948717948718, 'eval_runtime': 6.8346, 'eval_samples_per_second': 3.658, 'eval_steps_per_second': 1.024, 'epoch': 5.0}
{'loss': 0.6956, 'grad_norm': 1.568053126335144, 'learning_rate': 4.357142857142857e-06, 'epoch': 5.71}
{'eval_loss': 0.6907771825790405, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6217948717948718, 'eval_runtime': 5.208, 'eval_samples_per_second': 4.8, 'eval_steps_per_second': 1.344, 'epoch': 6.0}
{'loss': 0.6879, 'grad_norm': 0.8312633633613586, 'learning_rate': 3.642857142857143e-06, 'epoch': 6.43}
{'eval_loss': 0.6907811760902405, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6217948717948718, 'eval_runtime': 5.0544, 'eval_samples_per_second': 4.946, 'eval_steps_per_second': 1.385, 'epoch': 7.0}
{'loss': 0.6897, 'grad_norm': 0.8153071999549866, 'learning_rate': 2.928571428571429e-06, 'epoch': 7.14}
{'loss': 0.6884, 'grad_norm': 0.642270565032959, 'learning_rate': 2.2142857142857146e-06, 'epoch': 7.86}
{'eval_loss': 0.6907670497894287, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6217948717948718, 'eval_runtime': 4.9612, 'eval_samples_per_second': 5.039, 'eval_steps_per_second': 1.411, 'epoch': 8.0}
{'loss': 0.6911, 'grad_norm': 1.0796939134597778, 'learning_rate': 1.5e-06, 'epoch': 8.57}
{'eval_loss': 0.6907756924629211, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6217948717948718, 'eval_runtime': 4.9162, 'eval_samples_per_second': 5.085, 'eval_steps_per_second': 1.424, 'epoch': 9.0}
{'loss': 0.6927, 'grad_norm': 0.49082425236701965, 'learning_rate': 7.857142857142857e-07, 'epoch': 9.29}
{'loss': 0.6914, 'grad_norm': 0.9371256828308105, 'learning_rate': 7.142857142857144e-08, 'epoch': 10.0}
{'eval_loss': 0.6907742023468018, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6217948717948718, 'eval_runtime': 5.0357, 'eval_samples_per_second': 4.965, 'eval_steps_per_second': 1.39, 'epoch': 10.0}
{'train_runtime': 401.9538, 'train_samples_per_second': 1.393, 'train_steps_per_second': 0.348, 'train_loss': 0.6917584964207241, 'epoch': 10.0}
[CHECKPOINT] Best model @ artifacts/checkpoints/checkpoint-14
--- FINAL VALIDATION METRICS ---
accuracy  : 0.6
precision : 0.625
recall    : 0.4166666666666667
f1        : 0.5
roc_auc   : 0.6666666666666666
Confusion-matrix and ROC curve saved to artifacts/plots/
[INFO] Training complete.


EXECUTION TIME: 2025-05-15 15:16:48
[COMMENT] unfreeze top-2 at epoch 3
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 64000]) torch.float32 -1.1664526462554932 1.035493016242981
attention_mask torch.Size([2, 64000]) torch.int64 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6839)
any NaN? False
{'loss': 0.6971, 'grad_norm': 0.260749489068985, 'learning_rate': 9.357142857142859e-06, 'epoch': 0.71}
{'eval_loss': 0.690510094165802, 'eval_accuracy': 0.56, 'eval_precision': 0.5714285714285714, 'eval_recall': 0.3333333333333333, 'eval_f1': 0.42105263157894735, 'eval_roc_auc': 0.673076923076923, 'eval_runtime': 9.2527, 'eval_samples_per_second': 2.702, 'eval_steps_per_second': 0.757, 'epoch': 1.0}
{'loss': 0.6914, 'grad_norm': 5.41120719909668, 'learning_rate': 8.642857142857144e-06, 'epoch': 1.43}
{'eval_loss': 0.6905059814453125, 'eval_accuracy': 0.64, 'eval_precision': 0.6666666666666666, 'eval_recall': 0.5, 'eval_f1': 0.5714285714285714, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 4.9834, 'eval_samples_per_second': 5.017, 'eval_steps_per_second': 1.405, 'epoch': 2.0}
{'loss': 0.6944, 'grad_norm': 3.506944417953491, 'learning_rate': 7.928571428571429e-06, 'epoch': 2.14}
{'loss': 0.6922, 'grad_norm': 0.21847371757030487, 'learning_rate': 7.2142857142857145e-06, 'epoch': 2.86}
{'eval_loss': 0.690487802028656, 'eval_accuracy': 0.64, 'eval_precision': 0.6666666666666666, 'eval_recall': 0.5, 'eval_f1': 0.5714285714285714, 'eval_roc_auc': 0.6730769230769231, 'eval_runtime': 5.1883, 'eval_samples_per_second': 4.819, 'eval_steps_per_second': 1.349, 'epoch': 3.0}
[Callback] Un-froze top 2 layers at epoch 3. New trainable params: 36. LR scaled ×0.2
{'loss': 0.6934, 'grad_norm': 1.0812238454818726, 'learning_rate': 6.5000000000000004e-06, 'epoch': 3.57}
{'eval_loss': 0.6904465556144714, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6602564102564102, 'eval_runtime': 7.8512, 'eval_samples_per_second': 3.184, 'eval_steps_per_second': 0.892, 'epoch': 4.0}
{'loss': 0.6905, 'grad_norm': 1.1036626100540161, 'learning_rate': 5.785714285714286e-06, 'epoch': 4.29}
{'loss': 0.6912, 'grad_norm': 1.708675742149353, 'learning_rate': 5.071428571428571e-06, 'epoch': 5.0}
{'eval_loss': 0.6904512643814087, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6538461538461539, 'eval_runtime': 5.2598, 'eval_samples_per_second': 4.753, 'eval_steps_per_second': 1.331, 'epoch': 5.0}
{'loss': 0.6925, 'grad_norm': 1.8284002542495728, 'learning_rate': 4.357142857142857e-06, 'epoch': 5.71}
{'eval_loss': 0.6904476284980774, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6474358974358974, 'eval_runtime': 4.9924, 'eval_samples_per_second': 5.008, 'eval_steps_per_second': 1.402, 'epoch': 6.0}
{'loss': 0.6932, 'grad_norm': 0.7956463694572449, 'learning_rate': 3.642857142857143e-06, 'epoch': 6.43}
{'eval_loss': 0.6904565691947937, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.641025641025641, 'eval_runtime': 5.6175, 'eval_samples_per_second': 4.45, 'eval_steps_per_second': 1.246, 'epoch': 7.0}
{'loss': 0.6927, 'grad_norm': 0.805233359336853, 'learning_rate': 2.928571428571429e-06, 'epoch': 7.14}
{'loss': 0.6939, 'grad_norm': 0.33680474758148193, 'learning_rate': 2.2142857142857146e-06, 'epoch': 7.86}
{'eval_loss': 0.6904354095458984, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6538461538461539, 'eval_runtime': 5.1122, 'eval_samples_per_second': 4.89, 'eval_steps_per_second': 1.369, 'epoch': 8.0}
{'loss': 0.6927, 'grad_norm': 0.9791452288627625, 'learning_rate': 1.5e-06, 'epoch': 8.57}
{'eval_loss': 0.6904013156890869, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6602564102564102, 'eval_runtime': 5.3134, 'eval_samples_per_second': 4.705, 'eval_steps_per_second': 1.317, 'epoch': 9.0}
{'loss': 0.691, 'grad_norm': 0.3676902949810028, 'learning_rate': 7.857142857142857e-07, 'epoch': 9.29}
{'loss': 0.6957, 'grad_norm': 0.7811247110366821, 'learning_rate': 7.142857142857144e-08, 'epoch': 10.0}
{'eval_loss': 0.6903954148292542, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6538461538461539, 'eval_runtime': 4.9736, 'eval_samples_per_second': 5.027, 'eval_steps_per_second': 1.407, 'epoch': 10.0}
{'train_runtime': 423.0008, 'train_samples_per_second': 1.324, 'train_steps_per_second': 0.331, 'train_loss': 0.6930040972573417, 'epoch': 10.0}
[CHECKPOINT] Best model @ artifacts/checkpoints/checkpoint-42
--- FINAL VALIDATION METRICS ---
accuracy  : 0.64
precision : 0.6666666666666666
recall    : 0.5
f1        : 0.5714285714285714
roc_auc   : 0.6730769230769231
Confusion-matrix and ROC curve saved to artifacts/plots/
[INFO] Training complete.


EXECUTION TIME: 2025-05-15 15:45:12
[COMMENT] unfreeze top-4 at epoch 3
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 64000]) torch.float32 -1.1664526462554932 1.035493016242981
attention_mask torch.Size([2, 64000]) torch.int64 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6839)
any NaN? False
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.357142857142859e-06, 'epoch': 0.71}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 5.5842, 'eval_samples_per_second': 4.477, 'eval_steps_per_second': 1.254, 'epoch': 1.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 8.642857142857144e-06, 'epoch': 1.43}
{'eval_loss': nan, 'eval_accuracy': 0.52, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 5.4315, 'eval_samples_per_second': 4.603, 'eval_steps_per_second': 1.289, 'epoch': 2.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.928571428571429e-06, 'epoch': 2.14}
EXECUTION TIME: 2025-05-15 15:48:42
[COMMENT] unfreeze top-4 at epoch 3
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 64000]) torch.float32 -1.1664526462554932 1.035493016242981
attention_mask torch.Size([2, 64000]) torch.int64 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6839)
any NaN? False
{'loss': 0.6931, 'grad_norm': 0.3574638068675995, 'learning_rate': 9.357142857142859e-06, 'epoch': 0.71}
{'eval_loss': 0.6907294988632202, 'eval_accuracy': 0.6, 'eval_precision': 0.625, 'eval_recall': 0.4166666666666667, 'eval_f1': 0.5, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 5.1893, 'eval_samples_per_second': 4.818, 'eval_steps_per_second': 1.349, 'epoch': 1.0}
{'loss': 0.6953, 'grad_norm': 4.869986057281494, 'learning_rate': 8.642857142857144e-06, 'epoch': 1.43}
{'eval_loss': 0.6907522678375244, 'eval_accuracy': 0.68, 'eval_precision': 0.7, 'eval_recall': 0.5833333333333334, 'eval_f1': 0.6363636363636364, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 5.5984, 'eval_samples_per_second': 4.466, 'eval_steps_per_second': 1.25, 'epoch': 2.0}
{'loss': 0.693, 'grad_norm': 1.7849892377853394, 'learning_rate': 7.928571428571429e-06, 'epoch': 2.14}
{'loss': 0.693, 'grad_norm': 0.20990872383117676, 'learning_rate': 7.2142857142857145e-06, 'epoch': 2.86}
{'eval_loss': 0.6907914876937866, 'eval_accuracy': 0.64, 'eval_precision': 0.6363636363636364, 'eval_recall': 0.5833333333333334, 'eval_f1': 0.6086956521739131, 'eval_roc_auc': 0.6538461538461539, 'eval_runtime': 5.0484, 'eval_samples_per_second': 4.952, 'eval_steps_per_second': 1.387, 'epoch': 3.0}
[Callback] Un-froze top 2 layers at epoch 3. New trainable params: 36. LR scaled ×0.2
{'loss': 0.6892, 'grad_norm': 1.1133911609649658, 'learning_rate': 6.5000000000000004e-06, 'epoch': 3.57}
{'eval_loss': 0.6898086667060852, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6794871794871794, 'eval_runtime': 5.0183, 'eval_samples_per_second': 4.982, 'eval_steps_per_second': 1.395, 'epoch': 4.0}
{'loss': 0.6933, 'grad_norm': 1.1315224170684814, 'learning_rate': 5.785714285714286e-06, 'epoch': 4.29}
{'loss': 0.6925, 'grad_norm': 2.8888192176818848, 'learning_rate': 5.071428571428571e-06, 'epoch': 5.0}
{'eval_loss': 0.6895683407783508, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6217948717948718, 'eval_runtime': 5.1743, 'eval_samples_per_second': 4.832, 'eval_steps_per_second': 1.353, 'epoch': 5.0}
{'loss': 0.6957, 'grad_norm': 1.7230125665664673, 'learning_rate': 4.357142857142857e-06, 'epoch': 5.71}
EXECUTION TIME: 2025-05-15 15:52:14
[COMMENT] unfreeze top-4 at epoch 3
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 64000]) torch.float32 -1.1664526462554932 1.035493016242981
attention_mask torch.Size([2, 64000]) torch.int64 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6839)
any NaN? False
{'loss': 0.6931, 'grad_norm': 0.3574638068675995, 'learning_rate': 9.357142857142859e-06, 'epoch': 0.71}
{'eval_loss': 0.6907294988632202, 'eval_accuracy': 0.6, 'eval_precision': 0.625, 'eval_recall': 0.4166666666666667, 'eval_f1': 0.5, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 5.1044, 'eval_samples_per_second': 4.898, 'eval_steps_per_second': 1.371, 'epoch': 1.0}
{'loss': 0.6953, 'grad_norm': 4.869986057281494, 'learning_rate': 8.642857142857144e-06, 'epoch': 1.43}
{'eval_loss': 0.6907522678375244, 'eval_accuracy': 0.68, 'eval_precision': 0.7, 'eval_recall': 0.5833333333333334, 'eval_f1': 0.6363636363636364, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 5.5133, 'eval_samples_per_second': 4.534, 'eval_steps_per_second': 1.27, 'epoch': 2.0}
{'loss': 0.693, 'grad_norm': 1.7849892377853394, 'learning_rate': 7.928571428571429e-06, 'epoch': 2.14}
{'loss': 0.693, 'grad_norm': 0.20990872383117676, 'learning_rate': 7.2142857142857145e-06, 'epoch': 2.86}
{'eval_loss': 0.6907914876937866, 'eval_accuracy': 0.64, 'eval_precision': 0.6363636363636364, 'eval_recall': 0.5833333333333334, 'eval_f1': 0.6086956521739131, 'eval_roc_auc': 0.6538461538461539, 'eval_runtime': 5.1722, 'eval_samples_per_second': 4.833, 'eval_steps_per_second': 1.353, 'epoch': 3.0}
[Callback] Un-froze top 4 layers at epoch 3 → trainable params 68. LR now 0.00e+00 (warm-up 10 steps)
{'loss': 0.6892, 'grad_norm': 1.152631402015686, 'learning_rate': 6.5000000000000004e-06, 'epoch': 3.57}
{'eval_loss': 0.6887356638908386, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6987179487179488, 'eval_runtime': 5.0083, 'eval_samples_per_second': 4.992, 'eval_steps_per_second': 1.398, 'epoch': 4.0}
{'loss': 0.6936, 'grad_norm': 1.1705151796340942, 'learning_rate': 5.785714285714286e-06, 'epoch': 4.29}
{'loss': 0.6928, 'grad_norm': 2.8990530967712402, 'learning_rate': 5.071428571428571e-06, 'epoch': 5.0}
{'eval_loss': 0.6880624890327454, 'eval_accuracy': 0.48, 'eval_precision': 0.3333333333333333, 'eval_recall': 0.08333333333333333, 'eval_f1': 0.13333333333333333, 'eval_roc_auc': 0.6602564102564102, 'eval_runtime': 4.9191, 'eval_samples_per_second': 5.082, 'eval_steps_per_second': 1.423, 'epoch': 5.0}
{'loss': 0.696, 'grad_norm': 1.854214072227478, 'learning_rate': 4.357142857142857e-06, 'epoch': 5.71}
{'eval_loss': 0.6866765022277832, 'eval_accuracy': 0.56, 'eval_precision': 0.6, 'eval_recall': 0.25, 'eval_f1': 0.35294117647058826, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 4.9238, 'eval_samples_per_second': 5.077, 'eval_steps_per_second': 1.422, 'epoch': 6.0}
{'loss': 0.6854, 'grad_norm': 1.0293205976486206, 'learning_rate': 3.642857142857143e-06, 'epoch': 6.43}
{'eval_loss': 0.6860125064849854, 'eval_accuracy': 0.56, 'eval_precision': 0.6, 'eval_recall': 0.25, 'eval_f1': 0.35294117647058826, 'eval_roc_auc': 0.673076923076923, 'eval_runtime': 5.2447, 'eval_samples_per_second': 4.767, 'eval_steps_per_second': 1.335, 'epoch': 7.0}
{'loss': 0.685, 'grad_norm': 1.0064911842346191, 'learning_rate': 2.928571428571429e-06, 'epoch': 7.14}
{'loss': 0.6807, 'grad_norm': 0.8729081749916077, 'learning_rate': 2.2142857142857146e-06, 'epoch': 7.86}
{'eval_loss': 0.685085117816925, 'eval_accuracy': 0.56, 'eval_precision': 0.6, 'eval_recall': 0.25, 'eval_f1': 0.35294117647058826, 'eval_roc_auc': 0.673076923076923, 'eval_runtime': 5.5597, 'eval_samples_per_second': 4.497, 'eval_steps_per_second': 1.259, 'epoch': 8.0}
{'loss': 0.6888, 'grad_norm': 1.557466745376587, 'learning_rate': 1.5e-06, 'epoch': 8.57}
{'eval_loss': 0.684654712677002, 'eval_accuracy': 0.56, 'eval_precision': 0.6, 'eval_recall': 0.25, 'eval_f1': 0.35294117647058826, 'eval_roc_auc': 0.6602564102564102, 'eval_runtime': 5.7931, 'eval_samples_per_second': 4.315, 'eval_steps_per_second': 1.208, 'epoch': 9.0}
{'loss': 0.6899, 'grad_norm': 0.7488535642623901, 'learning_rate': 7.857142857142857e-07, 'epoch': 9.29}
{'loss': 0.6889, 'grad_norm': 1.2626659870147705, 'learning_rate': 7.142857142857144e-08, 'epoch': 10.0}
{'eval_loss': 0.6844345331192017, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6602564102564102, 'eval_runtime': 5.0966, 'eval_samples_per_second': 4.905, 'eval_steps_per_second': 1.373, 'epoch': 10.0}
{'train_runtime': 363.5081, 'train_samples_per_second': 1.541, 'train_steps_per_second': 0.385, 'train_loss': 0.6903342962265014, 'epoch': 10.0}
[CHECKPOINT] Best model @ artifacts/checkpoints/checkpoint-56
--- FINAL VALIDATION METRICS ---
accuracy  : 0.52
precision : 0.5
recall    : 0.25
f1        : 0.3333333333333333
roc_auc   : 0.6987179487179488
Confusion-matrix and ROC curve saved to artifacts/plots/
[INFO] Training complete.


EXECUTION TIME: 2025-05-15 16:01:09
[COMMENT] unfreeze top-4 at epoch 3
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 64000]) torch.float32 -1.1664526462554932 1.035493016242981
attention_mask torch.Size([2, 64000]) torch.int64 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6839)
any NaN? False
{'loss': 0.6931, 'grad_norm': 0.35740381479263306, 'learning_rate': 9.571428571428573e-06, 'epoch': 0.71}
{'eval_loss': 0.6907312273979187, 'eval_accuracy': 0.6, 'eval_precision': 0.625, 'eval_recall': 0.4166666666666667, 'eval_f1': 0.5, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 4.9352, 'eval_samples_per_second': 5.066, 'eval_steps_per_second': 1.418, 'epoch': 1.0}
{'loss': 0.6953, 'grad_norm': 4.870401382446289, 'learning_rate': 9.095238095238095e-06, 'epoch': 1.43}
{'eval_loss': 0.690755307674408, 'eval_accuracy': 0.68, 'eval_precision': 0.7, 'eval_recall': 0.5833333333333334, 'eval_f1': 0.6363636363636364, 'eval_roc_auc': 0.6538461538461539, 'eval_runtime': 4.9062, 'eval_samples_per_second': 5.096, 'eval_steps_per_second': 1.427, 'epoch': 2.0}
{'loss': 0.693, 'grad_norm': 1.7854233980178833, 'learning_rate': 8.61904761904762e-06, 'epoch': 2.14}
{'loss': 0.693, 'grad_norm': 0.20989122986793518, 'learning_rate': 8.142857142857143e-06, 'epoch': 2.86}
{'eval_loss': 0.6907986402511597, 'eval_accuracy': 0.64, 'eval_precision': 0.6363636363636364, 'eval_recall': 0.5833333333333334, 'eval_f1': 0.6086956521739131, 'eval_roc_auc': 0.6538461538461539, 'eval_runtime': 4.917, 'eval_samples_per_second': 5.084, 'eval_steps_per_second': 1.424, 'epoch': 3.0}
[Callback] Un-froze top 4 layers at epoch 3 → trainable tensors 68; head-LR 8.0e-06, encoder-LR 1.0e-05
{'loss': 0.6893, 'grad_norm': 1.0956332683563232, 'learning_rate': 7.666666666666667e-06, 'epoch': 3.57}
{'eval_loss': 0.6876782774925232, 'eval_accuracy': 0.48, 'eval_precision': 0.4, 'eval_recall': 0.16666666666666666, 'eval_f1': 0.23529411764705882, 'eval_roc_auc': 0.6987179487179487, 'eval_runtime': 4.9012, 'eval_samples_per_second': 5.101, 'eval_steps_per_second': 1.428, 'epoch': 4.0}
{'loss': 0.6937, 'grad_norm': 1.1571844816207886, 'learning_rate': 7.190476190476191e-06, 'epoch': 4.29}
{'loss': 0.6942, 'grad_norm': 2.8375020027160645, 'learning_rate': 6.714285714285714e-06, 'epoch': 5.0}
{'eval_loss': 0.6867951154708862, 'eval_accuracy': 0.48, 'eval_precision': 0.3333333333333333, 'eval_recall': 0.08333333333333333, 'eval_f1': 0.13333333333333333, 'eval_roc_auc': 0.6346153846153846, 'eval_runtime': 4.9169, 'eval_samples_per_second': 5.084, 'eval_steps_per_second': 1.424, 'epoch': 5.0}
{'loss': 0.6968, 'grad_norm': 2.0252885818481445, 'learning_rate': 6.238095238095239e-06, 'epoch': 5.71}
{'eval_loss': 0.6835020184516907, 'eval_accuracy': 0.48, 'eval_precision': 0.3333333333333333, 'eval_recall': 0.08333333333333333, 'eval_f1': 0.13333333333333333, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 4.9105, 'eval_samples_per_second': 5.091, 'eval_steps_per_second': 1.426, 'epoch': 6.0}
{'loss': 0.6835, 'grad_norm': 1.104157567024231, 'learning_rate': 5.761904761904762e-06, 'epoch': 6.43}
{'eval_loss': 0.6807831525802612, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.16666666666666666, 'eval_f1': 0.25, 'eval_roc_auc': 0.6602564102564102, 'eval_runtime': 4.9023, 'eval_samples_per_second': 5.1, 'eval_steps_per_second': 1.428, 'epoch': 7.0}
{'loss': 0.6802, 'grad_norm': 1.146106243133545, 'learning_rate': 5.285714285714286e-06, 'epoch': 7.14}
{'loss': 0.669, 'grad_norm': 1.5320640802383423, 'learning_rate': 4.80952380952381e-06, 'epoch': 7.86}
{'eval_loss': 0.6756011843681335, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.16666666666666666, 'eval_f1': 0.25, 'eval_roc_auc': 0.6858974358974359, 'eval_runtime': 4.9767, 'eval_samples_per_second': 5.023, 'eval_steps_per_second': 1.407, 'epoch': 8.0}
{'loss': 0.68, 'grad_norm': 2.583479642868042, 'learning_rate': 4.333333333333334e-06, 'epoch': 8.57}
{'eval_loss': 0.673147439956665, 'eval_accuracy': 0.56, 'eval_precision': 0.6, 'eval_recall': 0.25, 'eval_f1': 0.35294117647058826, 'eval_roc_auc': 0.6858974358974359, 'eval_runtime': 5.0754, 'eval_samples_per_second': 4.926, 'eval_steps_per_second': 1.379, 'epoch': 9.0}
{'loss': 0.6871, 'grad_norm': 1.9329512119293213, 'learning_rate': 3.857142857142858e-06, 'epoch': 9.29}
{'loss': 0.6862, 'grad_norm': 2.3902804851531982, 'learning_rate': 3.3809523809523814e-06, 'epoch': 10.0}
{'eval_loss': 0.6685845851898193, 'eval_accuracy': 0.56, 'eval_precision': 0.5714285714285714, 'eval_recall': 0.3333333333333333, 'eval_f1': 0.42105263157894735, 'eval_roc_auc': 0.6794871794871795, 'eval_runtime': 4.9223, 'eval_samples_per_second': 5.079, 'eval_steps_per_second': 1.422, 'epoch': 10.0}
{'loss': 0.6631, 'grad_norm': 1.1765497922897339, 'learning_rate': 2.9047619047619053e-06, 'epoch': 10.71}
{'eval_loss': 0.6696908473968506, 'eval_accuracy': 0.56, 'eval_precision': 0.6, 'eval_recall': 0.25, 'eval_f1': 0.35294117647058826, 'eval_roc_auc': 0.6730769230769231, 'eval_runtime': 4.9258, 'eval_samples_per_second': 5.075, 'eval_steps_per_second': 1.421, 'epoch': 11.0}
{'loss': 0.6778, 'grad_norm': 2.842090606689453, 'learning_rate': 2.428571428571429e-06, 'epoch': 11.43}
{'eval_loss': 0.6770145893096924, 'eval_accuracy': 0.56, 'eval_precision': 0.6, 'eval_recall': 0.25, 'eval_f1': 0.35294117647058826, 'eval_roc_auc': 0.6602564102564102, 'eval_runtime': 4.9302, 'eval_samples_per_second': 5.071, 'eval_steps_per_second': 1.42, 'epoch': 12.0}
{'loss': 0.678, 'grad_norm': 1.6314585208892822, 'learning_rate': 1.9523809523809527e-06, 'epoch': 12.14}
{'loss': 0.6858, 'grad_norm': 2.316129446029663, 'learning_rate': 1.4761904761904762e-06, 'epoch': 12.86}
{'eval_loss': 0.6770918965339661, 'eval_accuracy': 0.56, 'eval_precision': 0.6, 'eval_recall': 0.25, 'eval_f1': 0.35294117647058826, 'eval_roc_auc': 0.6282051282051282, 'eval_runtime': 4.9328, 'eval_samples_per_second': 5.068, 'eval_steps_per_second': 1.419, 'epoch': 13.0}
{'loss': 0.6767, 'grad_norm': 1.8030030727386475, 'learning_rate': 1.0000000000000002e-06, 'epoch': 13.57}
{'eval_loss': 0.6761627197265625, 'eval_accuracy': 0.56, 'eval_precision': 0.5714285714285714, 'eval_recall': 0.3333333333333333, 'eval_f1': 0.42105263157894735, 'eval_roc_auc': 0.6217948717948718, 'eval_runtime': 4.9749, 'eval_samples_per_second': 5.025, 'eval_steps_per_second': 1.407, 'epoch': 14.0}
{'loss': 0.6725, 'grad_norm': 2.588042974472046, 'learning_rate': 5.238095238095239e-07, 'epoch': 14.29}
{'loss': 0.6626, 'grad_norm': 2.7529444694519043, 'learning_rate': 4.7619047619047627e-08, 'epoch': 15.0}
{'eval_loss': 0.6818888783454895, 'eval_accuracy': 0.6, 'eval_precision': 0.6666666666666666, 'eval_recall': 0.3333333333333333, 'eval_f1': 0.4444444444444444, 'eval_roc_auc': 0.6153846153846154, 'eval_runtime': 4.9694, 'eval_samples_per_second': 5.031, 'eval_steps_per_second': 1.409, 'epoch': 15.0}
{'train_runtime': 515.8231, 'train_samples_per_second': 1.628, 'train_steps_per_second': 0.407, 'train_loss': 0.6833743731180827, 'epoch': 15.0}
[CHECKPOINT] Best model @ artifacts/checkpoints/checkpoint-56
--- FINAL VALIDATION METRICS ---
accuracy  : 0.48
precision : 0.4
recall    : 0.16666666666666666
f1        : 0.23529411764705882
roc_auc   : 0.6987179487179487
Confusion-matrix and ROC curve saved to artifacts/plots/
[INFO] Training complete.


EXECUTION TIME: 2025-05-20 17:21:25
[COMMENT] feature extractor frozen
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 64000]) torch.float32 -1.1664526462554932 1.035493016242981
attention_mask torch.Size([2, 64000]) torch.int64 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6839)
any NaN? False
{'loss': 0.6931, 'grad_norm': 0.35764798521995544, 'learning_rate': 8.92857142857143e-06, 'epoch': 0.71}
{'eval_loss': 0.6907261610031128, 'eval_accuracy': 0.6, 'eval_precision': 0.625, 'eval_recall': 0.4166666666666667, 'eval_f1': 0.5, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 7.8592, 'eval_samples_per_second': 3.181, 'eval_steps_per_second': 0.891, 'epoch': 1.0}
{'loss': 0.6952, 'grad_norm': 4.869166851043701, 'learning_rate': 7.738095238095238e-06, 'epoch': 1.43}
{'eval_loss': 0.6907460689544678, 'eval_accuracy': 0.68, 'eval_precision': 0.7, 'eval_recall': 0.5833333333333334, 'eval_f1': 0.6363636363636364, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 8.1486, 'eval_samples_per_second': 3.068, 'eval_steps_per_second': 0.859, 'epoch': 2.0}
[Callback] Un-froze top 6 layers at epoch 2 → trainable tensors 100; head-LR 6.7e-06, encoder-LR 1.0e-05
{'loss': 0.693, 'grad_norm': 1.900244951248169, 'learning_rate': 6.547619047619048e-06, 'epoch': 2.14}
{'loss': 0.6928, 'grad_norm': 0.5160406827926636, 'learning_rate': 5.357142857142857e-06, 'epoch': 2.86}
{'eval_loss': 0.689849853515625, 'eval_accuracy': 0.6, 'eval_precision': 0.6, 'eval_recall': 0.5, 'eval_f1': 0.5454545454545454, 'eval_roc_auc': 0.608974358974359, 'eval_runtime': 9.2434, 'eval_samples_per_second': 2.705, 'eval_steps_per_second': 0.757, 'epoch': 3.0}
{'loss': 0.6859, 'grad_norm': 1.1611435413360596, 'learning_rate': 4.166666666666667e-06, 'epoch': 3.57}
{'eval_loss': 0.6872950792312622, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6217948717948718, 'eval_runtime': 5.8127, 'eval_samples_per_second': 4.301, 'eval_steps_per_second': 1.204, 'epoch': 4.0}
{'loss': 0.6908, 'grad_norm': 1.3134175539016724, 'learning_rate': 2.9761904761904763e-06, 'epoch': 4.29}
{'loss': 0.6948, 'grad_norm': 2.972916603088379, 'learning_rate': 1.7857142857142859e-06, 'epoch': 5.0}
{'eval_loss': 0.6867190003395081, 'eval_accuracy': 0.48, 'eval_precision': 0.4, 'eval_recall': 0.16666666666666666, 'eval_f1': 0.23529411764705882, 'eval_roc_auc': 0.6217948717948718, 'eval_runtime': 6.3401, 'eval_samples_per_second': 3.943, 'eval_steps_per_second': 1.104, 'epoch': 5.0}
{'loss': 0.6957, 'grad_norm': 2.5623700618743896, 'learning_rate': 5.952380952380953e-07, 'epoch': 5.71}
{'eval_loss': 0.680614709854126, 'eval_accuracy': 0.6, 'eval_precision': 0.75, 'eval_recall': 0.25, 'eval_f1': 0.375, 'eval_roc_auc': 0.641025641025641, 'eval_runtime': 5.2691, 'eval_samples_per_second': 4.745, 'eval_steps_per_second': 1.328, 'epoch': 6.0}
{'train_runtime': 331.9353, 'train_samples_per_second': 1.012, 'train_steps_per_second': 0.253, 'train_loss': 0.6913770919754392, 'epoch': 6.0}
[CHECKPOINT] Best model @ artifacts/checkpoints/checkpoint-14
--- FINAL VALIDATION METRICS ---
accuracy  : 0.6
precision : 0.625
recall    : 0.4166666666666667
f1        : 0.5
roc_auc   : 0.6666666666666666
Confusion-matrix and ROC curve saved to artifacts/plots/
[INFO] Training complete.


EXECUTION TIME: 2025-05-20 17:34:41
[COMMENT] feature extractor frozen; fixed lr
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 64000]) torch.float32 -1.1664526462554932 1.035493016242981
attention_mask torch.Size([2, 64000]) torch.int64 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6839)
any NaN? False
EXECUTION TIME: 2025-05-20 17:36:59
[COMMENT] feature extractor frozen; fixed lr
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 64000]) torch.float32 -1.1664526462554932 1.035493016242981
attention_mask torch.Size([2, 64000]) torch.int64 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6839)
any NaN? False
{'loss': 0.6931, 'grad_norm': 0.35737425088882446, 'learning_rate': 9.678571428571429e-06, 'epoch': 0.71}
{'eval_loss': 0.690731942653656, 'eval_accuracy': 0.6, 'eval_precision': 0.625, 'eval_recall': 0.4166666666666667, 'eval_f1': 0.5, 'eval_roc_auc': 0.6666666666666666, 'eval_runtime': 4.7401, 'eval_samples_per_second': 5.274, 'eval_steps_per_second': 1.477, 'epoch': 1.0}
{'loss': 0.6953, 'grad_norm': 4.8706207275390625, 'learning_rate': 9.321428571428572e-06, 'epoch': 1.43}
{'eval_loss': 0.6907568573951721, 'eval_accuracy': 0.68, 'eval_precision': 0.7, 'eval_recall': 0.5833333333333334, 'eval_f1': 0.6363636363636364, 'eval_roc_auc': 0.6538461538461539, 'eval_runtime': 4.9426, 'eval_samples_per_second': 5.058, 'eval_steps_per_second': 1.416, 'epoch': 2.0}
{'loss': 0.693, 'grad_norm': 1.7856460809707642, 'learning_rate': 8.964285714285716e-06, 'epoch': 2.14}
{'loss': 0.693, 'grad_norm': 0.20988334715366364, 'learning_rate': 8.607142857142859e-06, 'epoch': 2.86}
{'eval_loss': 0.6908022165298462, 'eval_accuracy': 0.64, 'eval_precision': 0.6363636363636364, 'eval_recall': 0.5833333333333334, 'eval_f1': 0.6086956521739131, 'eval_roc_auc': 0.6538461538461539, 'eval_runtime': 5.1206, 'eval_samples_per_second': 4.882, 'eval_steps_per_second': 1.367, 'epoch': 3.0}
[Callback] Un-froze top 6 layers at epoch 3 → trainable tensors 100; head-LR 8.5e-06, encoder-LR 1.0e-05
{'loss': 0.6896, 'grad_norm': 1.1560758352279663, 'learning_rate': 8.25e-06, 'epoch': 3.57}
{'eval_loss': 0.6879966259002686, 'eval_accuracy': 0.48, 'eval_precision': 0.4, 'eval_recall': 0.16666666666666666, 'eval_f1': 0.23529411764705882, 'eval_roc_auc': 0.6858974358974359, 'eval_runtime': 5.0907, 'eval_samples_per_second': 4.911, 'eval_steps_per_second': 1.375, 'epoch': 4.0}
{'loss': 0.6939, 'grad_norm': 1.2484272718429565, 'learning_rate': 7.892857142857144e-06, 'epoch': 4.29}
{'loss': 0.6939, 'grad_norm': 2.7028660774230957, 'learning_rate': 7.5357142857142865e-06, 'epoch': 5.0}
{'eval_loss': 0.6872807145118713, 'eval_accuracy': 0.48, 'eval_precision': 0.3333333333333333, 'eval_recall': 0.08333333333333333, 'eval_f1': 0.13333333333333333, 'eval_roc_auc': 0.6153846153846154, 'eval_runtime': 5.006, 'eval_samples_per_second': 4.994, 'eval_steps_per_second': 1.398, 'epoch': 5.0}
{'loss': 0.6971, 'grad_norm': 2.2311177253723145, 'learning_rate': 7.178571428571429e-06, 'epoch': 5.71}
{'eval_loss': 0.6831409335136414, 'eval_accuracy': 0.56, 'eval_precision': 0.6666666666666666, 'eval_recall': 0.16666666666666666, 'eval_f1': 0.26666666666666666, 'eval_roc_auc': 0.6346153846153846, 'eval_runtime': 4.9535, 'eval_samples_per_second': 5.047, 'eval_steps_per_second': 1.413, 'epoch': 6.0}
{'loss': 0.6823, 'grad_norm': 1.204174518585205, 'learning_rate': 6.8214285714285724e-06, 'epoch': 6.43}
{'eval_loss': 0.6811469197273254, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.16666666666666666, 'eval_f1': 0.25, 'eval_roc_auc': 0.641025641025641, 'eval_runtime': 4.9255, 'eval_samples_per_second': 5.076, 'eval_steps_per_second': 1.421, 'epoch': 7.0}
{'loss': 0.6804, 'grad_norm': 1.7145378589630127, 'learning_rate': 6.464285714285715e-06, 'epoch': 7.14}
{'loss': 0.6651, 'grad_norm': 1.148704171180725, 'learning_rate': 6.107142857142858e-06, 'epoch': 7.86}
{'eval_loss': 0.680926501750946, 'eval_accuracy': 0.56, 'eval_precision': 0.6, 'eval_recall': 0.25, 'eval_f1': 0.35294117647058826, 'eval_roc_auc': 0.6538461538461539, 'eval_runtime': 4.9486, 'eval_samples_per_second': 5.052, 'eval_steps_per_second': 1.415, 'epoch': 8.0}
{'loss': 0.6781, 'grad_norm': 1.8145930767059326, 'learning_rate': 5.75e-06, 'epoch': 8.57}
{'eval_loss': 0.6784900426864624, 'eval_accuracy': 0.56, 'eval_precision': 0.6, 'eval_recall': 0.25, 'eval_f1': 0.35294117647058826, 'eval_roc_auc': 0.6474358974358974, 'eval_runtime': 4.9362, 'eval_samples_per_second': 5.065, 'eval_steps_per_second': 1.418, 'epoch': 9.0}
{'loss': 0.6807, 'grad_norm': 1.393369197845459, 'learning_rate': 5.392857142857143e-06, 'epoch': 9.29}
{'loss': 0.6835, 'grad_norm': 1.967828392982483, 'learning_rate': 5.035714285714286e-06, 'epoch': 10.0}
{'eval_loss': 0.6702033281326294, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.4166666666666667, 'eval_f1': 0.45454545454545453, 'eval_roc_auc': 0.641025641025641, 'eval_runtime': 5.4189, 'eval_samples_per_second': 4.613, 'eval_steps_per_second': 1.292, 'epoch': 10.0}
{'loss': 0.655, 'grad_norm': 1.9241384267807007, 'learning_rate': 4.678571428571429e-06, 'epoch': 10.71}
{'eval_loss': 0.6806495785713196, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.641025641025641, 'eval_runtime': 4.928, 'eval_samples_per_second': 5.073, 'eval_steps_per_second': 1.42, 'epoch': 11.0}
{'loss': 0.6816, 'grad_norm': 2.7995331287384033, 'learning_rate': 4.321428571428572e-06, 'epoch': 11.43}
{'eval_loss': 0.6890504360198975, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6410256410256411, 'eval_runtime': 5.0121, 'eval_samples_per_second': 4.988, 'eval_steps_per_second': 1.397, 'epoch': 12.0}
{'loss': 0.6824, 'grad_norm': 2.0098655223846436, 'learning_rate': 3.964285714285714e-06, 'epoch': 12.14}
{'loss': 0.6743, 'grad_norm': 2.408564567565918, 'learning_rate': 3.6071428571428573e-06, 'epoch': 12.86}
{'eval_loss': 0.6668861508369446, 'eval_accuracy': 0.48, 'eval_precision': 0.4444444444444444, 'eval_recall': 0.3333333333333333, 'eval_f1': 0.38095238095238093, 'eval_roc_auc': 0.6346153846153846, 'eval_runtime': 4.9324, 'eval_samples_per_second': 5.069, 'eval_steps_per_second': 1.419, 'epoch': 13.0}
{'loss': 0.6644, 'grad_norm': 1.7453491687774658, 'learning_rate': 3.2500000000000002e-06, 'epoch': 13.57}
{'eval_loss': 0.6625795960426331, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.5, 'eval_f1': 0.5, 'eval_roc_auc': 0.6282051282051282, 'eval_runtime': 4.9119, 'eval_samples_per_second': 5.09, 'eval_steps_per_second': 1.425, 'epoch': 14.0}
{'loss': 0.6699, 'grad_norm': 1.5397390127182007, 'learning_rate': 2.892857142857143e-06, 'epoch': 14.29}
{'loss': 0.6441, 'grad_norm': 2.9054336547851562, 'learning_rate': 2.5357142857142857e-06, 'epoch': 15.0}
{'eval_loss': 0.6999357342720032, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.25, 'eval_f1': 0.3333333333333333, 'eval_roc_auc': 0.6282051282051282, 'eval_runtime': 4.9476, 'eval_samples_per_second': 5.053, 'eval_steps_per_second': 1.415, 'epoch': 15.0}
{'loss': 0.6529, 'grad_norm': 1.2671087980270386, 'learning_rate': 2.1785714285714286e-06, 'epoch': 15.71}
{'eval_loss': 0.6773499250411987, 'eval_accuracy': 0.52, 'eval_precision': 0.5, 'eval_recall': 0.4166666666666667, 'eval_f1': 0.45454545454545453, 'eval_roc_auc': 0.6282051282051282, 'eval_runtime': 4.9535, 'eval_samples_per_second': 5.047, 'eval_steps_per_second': 1.413, 'epoch': 16.0}
{'loss': 0.6487, 'grad_norm': 1.5653141736984253, 'learning_rate': 1.8214285714285716e-06, 'epoch': 16.43}
{'eval_loss': 0.7060753107070923, 'eval_accuracy': 0.48, 'eval_precision': 0.4444444444444444, 'eval_recall': 0.3333333333333333, 'eval_f1': 0.38095238095238093, 'eval_roc_auc': 0.6089743589743589, 'eval_runtime': 4.9742, 'eval_samples_per_second': 5.026, 'eval_steps_per_second': 1.407, 'epoch': 17.0}
{'loss': 0.6445, 'grad_norm': 1.9519931077957153, 'learning_rate': 1.4642857142857145e-06, 'epoch': 17.14}
{'loss': 0.636, 'grad_norm': 3.880262851715088, 'learning_rate': 1.1071428571428573e-06, 'epoch': 17.86}
{'eval_loss': 0.7284142374992371, 'eval_accuracy': 0.44, 'eval_precision': 0.375, 'eval_recall': 0.25, 'eval_f1': 0.3, 'eval_roc_auc': 0.6025641025641025, 'eval_runtime': 4.9087, 'eval_samples_per_second': 5.093, 'eval_steps_per_second': 1.426, 'epoch': 18.0}
{'loss': 0.6057, 'grad_norm': 2.0115296840667725, 'learning_rate': 7.5e-07, 'epoch': 18.57}
{'eval_loss': 0.7317927479743958, 'eval_accuracy': 0.44, 'eval_precision': 0.375, 'eval_recall': 0.25, 'eval_f1': 0.3, 'eval_roc_auc': 0.6153846153846154, 'eval_runtime': 5.3494, 'eval_samples_per_second': 4.673, 'eval_steps_per_second': 1.309, 'epoch': 19.0}
{'loss': 0.6718, 'grad_norm': 2.0135486125946045, 'learning_rate': 3.9285714285714286e-07, 'epoch': 19.29}
{'loss': 0.6527, 'grad_norm': 3.006239175796509, 'learning_rate': 3.571428571428572e-08, 'epoch': 20.0}
{'eval_loss': 0.7256209850311279, 'eval_accuracy': 0.48, 'eval_precision': 0.4444444444444444, 'eval_recall': 0.3333333333333333, 'eval_f1': 0.38095238095238093, 'eval_roc_auc': 0.6282051282051282, 'eval_runtime': 5.1474, 'eval_samples_per_second': 4.857, 'eval_steps_per_second': 1.36, 'epoch': 20.0}
{'train_runtime': 739.1361, 'train_samples_per_second': 1.515, 'train_steps_per_second': 0.379, 'train_loss': 0.6715411492756435, 'epoch': 20.0}
[CHECKPOINT] Best model @ artifacts/checkpoints/checkpoint-56
--- FINAL VALIDATION METRICS ---
accuracy  : 0.48
precision : 0.4
recall    : 0.16666666666666666
f1        : 0.23529411764705882
roc_auc   : 0.6858974358974359
Confusion-matrix and ROC curve saved to artifacts/plots/
[INFO] Training complete.


[TIME] 2025-05-21 16:36:56
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.masked_spec_embed']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
input_values torch.Size([2, 64000]) torch.float32 -1.0651037693023682 1.037867546081543
attention_mask torch.Size([2, 64000]) torch.int64 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6888)
any NaN? False
{'loss': 0.6926, 'grad_norm': 0.270122230052948, 'learning_rate': 9.71875e-06, 'epoch': 0.31}                                                                                            
{'loss': 0.6905, 'grad_norm': 0.1754670888185501, 'learning_rate': 9.406250000000002e-06, 'epoch': 0.62}                                                                                 
{'loss': 0.6869, 'grad_norm': 0.9267460107803345, 'learning_rate': 9.09375e-06, 'epoch': 0.94}                                                                                           
{'eval_loss': 0.6874303221702576, 'eval_accuracy': 0.5185185185185185, 'eval_precision': 0.5238095238095238, 'eval_recall': 0.7857142857142857, 'eval_f1': 0.6285714285714286, 'eval_roc_auc': 0.6758241758241758, 'eval_runtime': 10.3235, 'eval_samples_per_second': 5.231, 'eval_steps_per_second': 1.356, 'epoch': 1.0}                                                       
{'loss': 0.6897, 'grad_norm': 0.8826501965522766, 'learning_rate': 8.781250000000002e-06, 'epoch': 1.25}                                                                                 
{'loss': 0.6792, 'grad_norm': 0.8186448216438293, 'learning_rate': 8.468750000000001e-06, 'epoch': 1.56}                                                                                 
{'loss': 0.688, 'grad_norm': 0.26077204942703247, 'learning_rate': 8.156250000000002e-06, 'epoch': 1.88}                                                                                 
{'eval_loss': 0.6857238411903381, 'eval_accuracy': 0.6481481481481481, 'eval_precision': 0.6285714285714286, 'eval_recall': 0.7857142857142857, 'eval_f1': 0.6984126984126984, 'eval_roc_auc': 0.6771978021978021, 'eval_runtime': 11.7146, 'eval_samples_per_second': 4.61, 'eval_steps_per_second': 1.195, 'epoch': 2.0}                                                        
{'loss': 0.6836, 'grad_norm': 0.2674628794193268, 'learning_rate': 7.843750000000001e-06, 'epoch': 2.19}                                                                                 
{'loss': 0.6806, 'grad_norm': 0.8839877843856812, 'learning_rate': 7.531250000000001e-06, 'epoch': 2.5}                                                                                  
{'loss': 0.6828, 'grad_norm': 0.21100308001041412, 'learning_rate': 7.218750000000001e-06, 'epoch': 2.81}                                                                                
{'eval_loss': 0.6844123601913452, 'eval_accuracy': 0.5, 'eval_precision': 0.5106382978723404, 'eval_recall': 0.8571428571428571, 'eval_f1': 0.64, 'eval_roc_auc': 0.6881868131868132, 'eval_runtime': 10.907, 'eval_samples_per_second': 4.951, 'eval_steps_per_second': 1.284, 'epoch': 3.0}                                                                                     
{'loss': 0.6865, 'grad_norm': 1.2059139013290405, 'learning_rate': 6.906250000000001e-06, 'epoch': 3.12}                                                                                 
{'loss': 0.677, 'grad_norm': 0.2595614790916443, 'learning_rate': 6.593750000000001e-06, 'epoch': 3.44}                                                                                  
{'loss': 0.6962, 'grad_norm': 0.895748496055603, 'learning_rate': 6.281250000000001e-06, 'epoch': 3.75}                                                                                  
{'eval_loss': 0.6834338903427124, 'eval_accuracy': 0.5370370370370371, 'eval_precision': 0.5333333333333333, 'eval_recall': 0.8571428571428571, 'eval_f1': 0.6575342465753424, 'eval_roc_auc': 0.6936813186813187, 'eval_runtime': 11.0298, 'eval_samples_per_second': 4.896, 'eval_steps_per_second': 1.269, 'epoch': 4.0}                                                       
{'loss': 0.6823, 'grad_norm': 0.7088893055915833, 'learning_rate': 5.968750000000001e-06, 'epoch': 4.06}                                                                                 
{'loss': 0.6864, 'grad_norm': 0.7447928190231323, 'learning_rate': 5.656250000000001e-06, 'epoch': 4.38}                                                                                 
{'loss': 0.6742, 'grad_norm': 0.8786716461181641, 'learning_rate': 5.343750000000001e-06, 'epoch': 4.69}                                                                                 
{'loss': 0.6883, 'grad_norm': 1.5835223197937012, 'learning_rate': 5.031250000000001e-06, 'epoch': 5.0}                                                                                  
{'eval_loss': 0.6821615695953369, 'eval_accuracy': 0.6481481481481481, 'eval_precision': 0.6216216216216216, 'eval_recall': 0.8214285714285714, 'eval_f1': 0.7076923076923077, 'eval_roc_auc': 0.6991758241758241, 'eval_runtime': 10.9818, 'eval_samples_per_second': 4.917, 'eval_steps_per_second': 1.275, 'epoch': 5.0}                                                       
{'loss': 0.685, 'grad_norm': 1.0206316709518433, 'learning_rate': 4.71875e-06, 'epoch': 5.31}                                                                                            
{'loss': 0.6881, 'grad_norm': 1.0862582921981812, 'learning_rate': 4.40625e-06, 'epoch': 5.62}                                                                                           
{'loss': 0.6862, 'grad_norm': 0.32049694657325745, 'learning_rate': 4.09375e-06, 'epoch': 5.94}                                                                                          
{'eval_loss': 0.6813110113143921, 'eval_accuracy': 0.6481481481481481, 'eval_precision': 0.6216216216216216, 'eval_recall': 0.8214285714285714, 'eval_f1': 0.7076923076923077, 'eval_roc_auc': 0.7046703296703296, 'eval_runtime': 11.0154, 'eval_samples_per_second': 4.902, 'eval_steps_per_second': 1.271, 'epoch': 6.0}                                                       
{'loss': 0.6819, 'grad_norm': 0.8778424263000488, 'learning_rate': 3.78125e-06, 'epoch': 6.25}                                                                                           
{'loss': 0.6911, 'grad_norm': 1.0303176641464233, 'learning_rate': 3.46875e-06, 'epoch': 6.56}                                                                                           
{'loss': 0.6794, 'grad_norm': 1.5725864171981812, 'learning_rate': 3.15625e-06, 'epoch': 6.88}                                                                                           
{'eval_loss': 0.6806973814964294, 'eval_accuracy': 0.6481481481481481, 'eval_precision': 0.6216216216216216, 'eval_recall': 0.8214285714285714, 'eval_f1': 0.7076923076923077, 'eval_roc_auc': 0.7060439560439561, 'eval_runtime': 10.9325, 'eval_samples_per_second': 4.939, 'eval_steps_per_second': 1.281, 'epoch': 7.0}                                                       
{'loss': 0.6849, 'grad_norm': 1.1119558811187744, 'learning_rate': 2.84375e-06, 'epoch': 7.19}                                                                                           
{'loss': 0.6869, 'grad_norm': 0.7741551995277405, 'learning_rate': 2.53125e-06, 'epoch': 7.5}                                                                                            
{'loss': 0.6839, 'grad_norm': 0.245638906955719, 'learning_rate': 2.21875e-06, 'epoch': 7.81}                                                                                            
{'eval_loss': 0.6801515221595764, 'eval_accuracy': 0.6481481481481481, 'eval_precision': 0.6216216216216216, 'eval_recall': 0.8214285714285714, 'eval_f1': 0.7076923076923077, 'eval_roc_auc': 0.7032967032967034, 'eval_runtime': 12.4721, 'eval_samples_per_second': 4.33, 'eval_steps_per_second': 1.123, 'epoch': 8.0}                                                        
{'loss': 0.688, 'grad_norm': 0.23105181753635406, 'learning_rate': 1.90625e-06, 'epoch': 8.12}                                                                                           
{'loss': 0.6757, 'grad_norm': 1.3996275663375854, 'learning_rate': 1.59375e-06, 'epoch': 8.44}                                                                                           
{'loss': 0.6865, 'grad_norm': 1.0397405624389648, 'learning_rate': 1.28125e-06, 'epoch': 8.75}                                                                                           
{'eval_loss': 0.679836630821228, 'eval_accuracy': 0.6481481481481481, 'eval_precision': 0.6216216216216216, 'eval_recall': 0.8214285714285714, 'eval_f1': 0.7076923076923077, 'eval_roc_auc': 0.7074175824175825, 'eval_runtime': 11.2857, 'eval_samples_per_second': 4.785, 'eval_steps_per_second': 1.241, 'epoch': 9.0}                                                        
{'loss': 0.6871, 'grad_norm': 1.664733648300171, 'learning_rate': 9.6875e-07, 'epoch': 9.06}                                                                                             
{'loss': 0.6767, 'grad_norm': 0.8361737728118896, 'learning_rate': 6.562500000000001e-07, 'epoch': 9.38}                                                                                 
{'loss': 0.6773, 'grad_norm': 1.5015902519226074, 'learning_rate': 3.4375000000000004e-07, 'epoch': 9.69}                                                                                
{'loss': 0.6921, 'grad_norm': 0.36724868416786194, 'learning_rate': 3.1250000000000005e-08, 'epoch': 10.0}                                                                               
{'eval_loss': 0.6797527074813843, 'eval_accuracy': 0.6481481481481481, 'eval_precision': 0.6216216216216216, 'eval_recall': 0.8214285714285714, 'eval_f1': 0.7076923076923077, 'eval_roc_auc': 0.7060439560439561, 'eval_runtime': 11.1644, 'eval_samples_per_second': 4.837, 'eval_steps_per_second': 1.254, 'epoch': 10.0}                                                      
{'train_runtime': 865.8441, 'train_samples_per_second': 1.455, 'train_steps_per_second': 0.37, 'train_loss': 0.6848627269268036, 'epoch': 10.0}                                          
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [14:25<00:00,  2.71s/it]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:10<00:00,  1.33it/s]
[CHECKPOINT] Best model @ artifacts/checkpoints/checkpoint-288
--- FINAL VALIDATION METRICS ---
accuracy  : 0.6481481481481481
precision : 0.6216216216216216
recall    : 0.8214285714285714
f1        : 0.7076923076923077
roc_auc   : 0.7074175824175825
Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.
Confusion-matrix and ROC curve saved to artifacts/plots/
[INFO] Training complete.
[TIME] 2025-05-21 18:10:42
[COMMENT] 20 epoch, freeze feautre extr, no mild augment, 8 sec duration
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 128000]) torch.float32 -1.0651037693023682 1.037867546081543
attention_mask torch.Size([2, 128000]) torch.int64 1 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6785)
any NaN? False
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.71875e-06, 'epoch': 0.31}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.406250000000002e-06, 'epoch': 0.62}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.09375e-06, 'epoch': 0.94}
{'eval_loss': nan, 'eval_accuracy': 0.48148148148148145, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 44.163, 'eval_samples_per_second': 1.223, 'eval_steps_per_second': 0.317, 'epoch': 1.0}
[TIME] 2025-05-21 18:28:21
[COMMENT] 10 epoch, freeze feautre extr, no mild augment, 4 sec duration
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 64000]) torch.float32 -1.0651037693023682 1.037867546081543
attention_mask torch.Size([2, 64000]) torch.int64 0 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6730)
any NaN? False
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.71875e-06, 'epoch': 0.31}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.406250000000002e-06, 'epoch': 0.62}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.09375e-06, 'epoch': 0.94}
{'eval_loss': nan, 'eval_accuracy': 0.48148148148148145, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 42.805, 'eval_samples_per_second': 1.262, 'eval_steps_per_second': 0.327, 'epoch': 1.0}
[TIME] 2025-05-21 18:36:08
[COMMENT] 10 epoch, freeze feautre extr, no mild augment, 4 sec duration
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 64000]) torch.float32 -1.0651037693023682 1.037867546081543
attention_mask torch.Size([2, 64000]) torch.int64 0 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6730)
any NaN? False
{'loss': 0.6899, 'grad_norm': 0.5275557041168213, 'learning_rate': 9.71875e-06, 'epoch': 0.31}
{'loss': 0.6903, 'grad_norm': 0.5338255763053894, 'learning_rate': 9.406250000000002e-06, 'epoch': 0.62}
{'loss': 0.6885, 'grad_norm': 0.9773221611976624, 'learning_rate': 9.09375e-06, 'epoch': 0.94}
{'eval_loss': 0.6887829303741455, 'eval_accuracy': 0.5925925925925926, 'eval_precision': 0.56, 'eval_recall': 1.0, 'eval_f1': 0.717948717948718, 'eval_roc_auc': 0.6456043956043956, 'eval_runtime': 26.279, 'eval_samples_per_second': 2.055, 'eval_steps_per_second': 0.533, 'epoch': 1.0}
{'loss': 0.6949, 'grad_norm': 1.3579589128494263, 'learning_rate': 8.781250000000002e-06, 'epoch': 1.25}
{'loss': 0.6906, 'grad_norm': 0.6542232632637024, 'learning_rate': 8.468750000000001e-06, 'epoch': 1.56}
{'loss': 0.6936, 'grad_norm': 0.3060479462146759, 'learning_rate': 8.156250000000002e-06, 'epoch': 1.88}
{'eval_loss': 0.6869961619377136, 'eval_accuracy': 0.6851851851851852, 'eval_precision': 0.6410256410256411, 'eval_recall': 0.8928571428571429, 'eval_f1': 0.746268656716418, 'eval_roc_auc': 0.6744505494505495, 'eval_runtime': 63.2737, 'eval_samples_per_second': 0.853, 'eval_steps_per_second': 0.221, 'epoch': 2.0}
{'loss': 0.6908, 'grad_norm': 0.20905865728855133, 'learning_rate': 7.843750000000001e-06, 'epoch': 2.19}
{'loss': 0.6911, 'grad_norm': 0.8493281602859497, 'learning_rate': 7.531250000000001e-06, 'epoch': 2.5}
{'loss': 0.691, 'grad_norm': 0.2043936848640442, 'learning_rate': 7.218750000000001e-06, 'epoch': 2.81}
{'eval_loss': 0.6862853765487671, 'eval_accuracy': 0.6296296296296297, 'eval_precision': 0.5833333333333334, 'eval_recall': 1.0, 'eval_f1': 0.7368421052631579, 'eval_roc_auc': 0.6854395604395604, 'eval_runtime': 39.3277, 'eval_samples_per_second': 1.373, 'eval_steps_per_second': 0.356, 'epoch': 3.0}
{'loss': 0.6922, 'grad_norm': 0.7644197940826416, 'learning_rate': 6.906250000000001e-06, 'epoch': 3.12}
{'loss': 0.6864, 'grad_norm': 0.30667126178741455, 'learning_rate': 6.593750000000001e-06, 'epoch': 3.44}
{'loss': 0.6927, 'grad_norm': 0.9268686771392822, 'learning_rate': 6.281250000000001e-06, 'epoch': 3.75}
{'eval_loss': 0.6857494711875916, 'eval_accuracy': 0.6296296296296297, 'eval_precision': 0.5833333333333334, 'eval_recall': 1.0, 'eval_f1': 0.7368421052631579, 'eval_roc_auc': 0.6840659340659341, 'eval_runtime': 12.2294, 'eval_samples_per_second': 4.416, 'eval_steps_per_second': 1.145, 'epoch': 4.0}
{'loss': 0.6893, 'grad_norm': 0.8602374792098999, 'learning_rate': 5.968750000000001e-06, 'epoch': 4.06}
{'loss': 0.6872, 'grad_norm': 0.7223372459411621, 'learning_rate': 5.656250000000001e-06, 'epoch': 4.38}
{'loss': 0.685, 'grad_norm': 0.9308367967605591, 'learning_rate': 5.343750000000001e-06, 'epoch': 4.69}
{'loss': 0.6938, 'grad_norm': 1.5030649900436401, 'learning_rate': 5.031250000000001e-06, 'epoch': 5.0}
{'eval_loss': 0.6849701404571533, 'eval_accuracy': 0.6296296296296297, 'eval_precision': 0.5833333333333334, 'eval_recall': 1.0, 'eval_f1': 0.7368421052631579, 'eval_roc_auc': 0.6978021978021978, 'eval_runtime': 13.1776, 'eval_samples_per_second': 4.098, 'eval_steps_per_second': 1.062, 'epoch': 5.0}
{'loss': 0.6902, 'grad_norm': 2.5022919178009033, 'learning_rate': 4.71875e-06, 'epoch': 5.31}
{'loss': 0.6893, 'grad_norm': 0.793408215045929, 'learning_rate': 4.40625e-06, 'epoch': 5.62}
{'loss': 0.6866, 'grad_norm': 0.2671787738800049, 'learning_rate': 4.09375e-06, 'epoch': 5.94}
{'eval_loss': 0.6846340298652649, 'eval_accuracy': 0.6296296296296297, 'eval_precision': 0.5833333333333334, 'eval_recall': 1.0, 'eval_f1': 0.7368421052631579, 'eval_roc_auc': 0.7005494505494505, 'eval_runtime': 14.4126, 'eval_samples_per_second': 3.747, 'eval_steps_per_second': 0.971, 'epoch': 6.0}
{'loss': 0.6813, 'grad_norm': 0.6906962394714355, 'learning_rate': 3.78125e-06, 'epoch': 6.25}
{'loss': 0.6913, 'grad_norm': 0.8637426495552063, 'learning_rate': 3.46875e-06, 'epoch': 6.56}
{'loss': 0.686, 'grad_norm': 0.2167077213525772, 'learning_rate': 3.15625e-06, 'epoch': 6.88}
{'eval_loss': 0.6843131184577942, 'eval_accuracy': 0.6296296296296297, 'eval_precision': 0.5833333333333334, 'eval_recall': 1.0, 'eval_f1': 0.7368421052631579, 'eval_roc_auc': 0.7032967032967034, 'eval_runtime': 12.5537, 'eval_samples_per_second': 4.302, 'eval_steps_per_second': 1.115, 'epoch': 7.0}
{'loss': 0.693, 'grad_norm': 1.0833261013031006, 'learning_rate': 2.84375e-06, 'epoch': 7.19}
{'loss': 0.6871, 'grad_norm': 0.9225011467933655, 'learning_rate': 2.53125e-06, 'epoch': 7.5}
{'loss': 0.6947, 'grad_norm': 0.48407289385795593, 'learning_rate': 2.21875e-06, 'epoch': 7.81}
{'eval_loss': 0.6838760375976562, 'eval_accuracy': 0.6296296296296297, 'eval_precision': 0.5833333333333334, 'eval_recall': 1.0, 'eval_f1': 0.7368421052631579, 'eval_roc_auc': 0.7046703296703296, 'eval_runtime': 14.0302, 'eval_samples_per_second': 3.849, 'eval_steps_per_second': 0.998, 'epoch': 8.0}
{'loss': 0.6959, 'grad_norm': 0.38734546303749084, 'learning_rate': 1.90625e-06, 'epoch': 8.12}
{'loss': 0.6835, 'grad_norm': 1.539189338684082, 'learning_rate': 1.59375e-06, 'epoch': 8.44}
{'loss': 0.6853, 'grad_norm': 0.7403001189231873, 'learning_rate': 1.28125e-06, 'epoch': 8.75}
{'eval_loss': 0.6836891174316406, 'eval_accuracy': 0.6296296296296297, 'eval_precision': 0.5833333333333334, 'eval_recall': 1.0, 'eval_f1': 0.7368421052631579, 'eval_roc_auc': 0.7074175824175825, 'eval_runtime': 12.1573, 'eval_samples_per_second': 4.442, 'eval_steps_per_second': 1.152, 'epoch': 9.0}
{'loss': 0.6886, 'grad_norm': 1.5854849815368652, 'learning_rate': 9.6875e-07, 'epoch': 9.06}
{'loss': 0.6881, 'grad_norm': 0.7274660468101501, 'learning_rate': 6.562500000000001e-07, 'epoch': 9.38}
{'loss': 0.6828, 'grad_norm': 1.4066987037658691, 'learning_rate': 3.4375000000000004e-07, 'epoch': 9.69}
{'loss': 0.6868, 'grad_norm': 0.27148962020874023, 'learning_rate': 3.1250000000000005e-08, 'epoch': 10.0}
{'eval_loss': 0.6836153864860535, 'eval_accuracy': 0.6296296296296297, 'eval_precision': 0.5833333333333334, 'eval_recall': 1.0, 'eval_f1': 0.7368421052631579, 'eval_roc_auc': 0.7074175824175825, 'eval_runtime': 12.062, 'eval_samples_per_second': 4.477, 'eval_steps_per_second': 1.161, 'epoch': 10.0}
{'train_runtime': 1292.3004, 'train_samples_per_second': 0.975, 'train_steps_per_second': 0.248, 'train_loss': 0.689311258494854, 'epoch': 10.0}
[CHECKPOINT] Best model @ artifacts/checkpoints/checkpoint-288
--- FINAL VALIDATION METRICS ---
accuracy  : 0.6296296296296297
precision : 0.5833333333333334
recall    : 1.0
f1        : 0.7368421052631579
roc_auc   : 0.7074175824175825
Confusion-matrix and ROC curve saved to artifacts/plots/
[INFO] Training complete.


[TIME] 2025-05-21 18:58:55
[COMMENT] 10 epoch, freeze feautre extr, no mild augment, 8 sec duration
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 128000]) torch.float32 -1.0651037693023682 1.037867546081543
attention_mask torch.Size([2, 128000]) torch.int64 0 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6797)
any NaN? False
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.71875e-06, 'epoch': 0.31}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.406250000000002e-06, 'epoch': 0.62}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.09375e-06, 'epoch': 0.94}
{'eval_loss': nan, 'eval_accuracy': 0.48148148148148145, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 23.3883, 'eval_samples_per_second': 2.309, 'eval_steps_per_second': 0.599, 'epoch': 1.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 8.781250000000002e-06, 'epoch': 1.25}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 8.468750000000001e-06, 'epoch': 1.56}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 8.156250000000002e-06, 'epoch': 1.88}
{'eval_loss': nan, 'eval_accuracy': 0.48148148148148145, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 23.1364, 'eval_samples_per_second': 2.334, 'eval_steps_per_second': 0.605, 'epoch': 2.0}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.843750000000001e-06, 'epoch': 2.19}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.531250000000001e-06, 'epoch': 2.5}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 7.218750000000001e-06, 'epoch': 2.81}
[TIME] 2025-05-21 19:07:10
[COMMENT] 10 epoch, freeze feautre extr, no mild augment, 8 sec duration
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 128000]) torch.float32 -1.0651037693023682 1.037867546081543
attention_mask torch.Size([2, 128000]) torch.int64 0 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6797)
any NaN? False
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.71875e-06, 'epoch': 0.31}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.406250000000002e-06, 'epoch': 0.62}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 9.09375e-06, 'epoch': 0.94}
{'eval_loss': nan, 'eval_accuracy': 0.48148148148148145, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_roc_auc': nan, 'eval_runtime': 23.5758, 'eval_samples_per_second': 2.29, 'eval_steps_per_second': 0.594, 'epoch': 1.0}
[TIME] 2025-05-21 19:11:17
[COMMENT] 10 epoch, freeze feautre extr, no mild augment, 8 sec duration
[INFO] Using device: cpu
[INFO] Using Wav2Vec2 model: facebook/wav2vec2-base-960h
--------------ENVIRONMENT-----------------
🤗 Transformers version : 4.51.3
package imported from  : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers
TrainingArguments file : /home/tommaso/anaconda3/lib/python3.12/site-packages/transformers/training_args.py
------------------------------------------
input_values torch.Size([2, 80000]) torch.float32 -1.0651037693023682 1.037867546081543
attention_mask torch.Size([2, 80000]) torch.int64 0 1
labels torch.Size([2]) torch.int64 1 1
forward  →  loss: tensor(0.6768)
any NaN? False
{'loss': 0.6902, 'grad_norm': 0.4189611077308655, 'learning_rate': 9.71875e-06, 'epoch': 0.31}
{'loss': 0.6879, 'grad_norm': 0.576300859451294, 'learning_rate': 9.406250000000002e-06, 'epoch': 0.62}
{'loss': 0.6902, 'grad_norm': 1.0011717081069946, 'learning_rate': 9.09375e-06, 'epoch': 0.94}
{'eval_loss': 0.6890308260917664, 'eval_accuracy': 0.5370370370370371, 'eval_precision': 0.5306122448979592, 'eval_recall': 0.9285714285714286, 'eval_f1': 0.6753246753246753, 'eval_roc_auc': 0.6813186813186813, 'eval_runtime': 14.4972, 'eval_samples_per_second': 3.725, 'eval_steps_per_second': 0.966, 'epoch': 1.0}
{'loss': 0.6961, 'grad_norm': 1.248425006866455, 'learning_rate': 8.781250000000002e-06, 'epoch': 1.25}
{'loss': 0.6912, 'grad_norm': 0.66718590259552, 'learning_rate': 8.468750000000001e-06, 'epoch': 1.56}
{'loss': 0.6918, 'grad_norm': 0.3077353835105896, 'learning_rate': 8.156250000000002e-06, 'epoch': 1.88}
{'eval_loss': 0.687686026096344, 'eval_accuracy': 0.6481481481481481, 'eval_precision': 0.6097560975609756, 'eval_recall': 0.8928571428571429, 'eval_f1': 0.7246376811594203, 'eval_roc_auc': 0.6978021978021978, 'eval_runtime': 16.0517, 'eval_samples_per_second': 3.364, 'eval_steps_per_second': 0.872, 'epoch': 2.0}
{'loss': 0.6881, 'grad_norm': 0.20415614545345306, 'learning_rate': 7.843750000000001e-06, 'epoch': 2.19}
{'loss': 0.6922, 'grad_norm': 0.7740615010261536, 'learning_rate': 7.531250000000001e-06, 'epoch': 2.5}
{'loss': 0.6913, 'grad_norm': 0.18793247640132904, 'learning_rate': 7.218750000000001e-06, 'epoch': 2.81}
{'eval_loss': 0.6868705749511719, 'eval_accuracy': 0.5555555555555556, 'eval_precision': 0.5416666666666666, 'eval_recall': 0.9285714285714286, 'eval_f1': 0.6842105263157895, 'eval_roc_auc': 0.7032967032967034, 'eval_runtime': 14.3384, 'eval_samples_per_second': 3.766, 'eval_steps_per_second': 0.976, 'epoch': 3.0}
{'loss': 0.6917, 'grad_norm': 0.8057671785354614, 'learning_rate': 6.906250000000001e-06, 'epoch': 3.12}
{'loss': 0.685, 'grad_norm': 0.2778841257095337, 'learning_rate': 6.593750000000001e-06, 'epoch': 3.44}
{'loss': 0.692, 'grad_norm': 0.8391033411026001, 'learning_rate': 6.281250000000001e-06, 'epoch': 3.75}
{'eval_loss': 0.6861158013343811, 'eval_accuracy': 0.5370370370370371, 'eval_precision': 0.5306122448979592, 'eval_recall': 0.9285714285714286, 'eval_f1': 0.6753246753246753, 'eval_roc_auc': 0.7129120879120879, 'eval_runtime': 13.5343, 'eval_samples_per_second': 3.99, 'eval_steps_per_second': 1.034, 'epoch': 4.0}
{'loss': 0.6892, 'grad_norm': 0.879866898059845, 'learning_rate': 5.968750000000001e-06, 'epoch': 4.06}
{'loss': 0.6863, 'grad_norm': 0.7692628502845764, 'learning_rate': 5.656250000000001e-06, 'epoch': 4.38}
{'loss': 0.6841, 'grad_norm': 0.9276773929595947, 'learning_rate': 5.343750000000001e-06, 'epoch': 4.69}
{'loss': 0.6914, 'grad_norm': 1.4651267528533936, 'learning_rate': 5.031250000000001e-06, 'epoch': 5.0}
{'eval_loss': 0.6852337718009949, 'eval_accuracy': 0.5740740740740741, 'eval_precision': 0.5531914893617021, 'eval_recall': 0.9285714285714286, 'eval_f1': 0.6933333333333334, 'eval_roc_auc': 0.7197802197802198, 'eval_runtime': 14.8165, 'eval_samples_per_second': 3.645, 'eval_steps_per_second': 0.945, 'epoch': 5.0}
{'loss': 0.6918, 'grad_norm': 1.8119412660598755, 'learning_rate': 4.71875e-06, 'epoch': 5.31}
{'loss': 0.6897, 'grad_norm': 0.7958440780639648, 'learning_rate': 4.40625e-06, 'epoch': 5.62}
{'loss': 0.686, 'grad_norm': 0.3049926459789276, 'learning_rate': 4.09375e-06, 'epoch': 5.94}
{'eval_loss': 0.6848064064979553, 'eval_accuracy': 0.6296296296296297, 'eval_precision': 0.5909090909090909, 'eval_recall': 0.9285714285714286, 'eval_f1': 0.7222222222222222, 'eval_roc_auc': 0.7239010989010989, 'eval_runtime': 14.2944, 'eval_samples_per_second': 3.778, 'eval_steps_per_second': 0.979, 'epoch': 6.0}
{'loss': 0.6843, 'grad_norm': 0.6472339630126953, 'learning_rate': 3.78125e-06, 'epoch': 6.25}
{'loss': 0.6923, 'grad_norm': 0.8164888620376587, 'learning_rate': 3.46875e-06, 'epoch': 6.56}
{'loss': 0.6853, 'grad_norm': 0.22030293941497803, 'learning_rate': 3.15625e-06, 'epoch': 6.88}
{'eval_loss': 0.6845706701278687, 'eval_accuracy': 0.5925925925925926, 'eval_precision': 0.5652173913043478, 'eval_recall': 0.9285714285714286, 'eval_f1': 0.7027027027027027, 'eval_roc_auc': 0.7225274725274725, 'eval_runtime': 17.9528, 'eval_samples_per_second': 3.008, 'eval_steps_per_second': 0.78, 'epoch': 7.0}
{'loss': 0.6937, 'grad_norm': 1.1181329488754272, 'learning_rate': 2.84375e-06, 'epoch': 7.19}
{'loss': 0.6878, 'grad_norm': 0.9407520890235901, 'learning_rate': 2.53125e-06, 'epoch': 7.5}
{'loss': 0.6936, 'grad_norm': 0.541771650314331, 'learning_rate': 2.21875e-06, 'epoch': 7.81}
{'eval_loss': 0.6841825842857361, 'eval_accuracy': 0.6111111111111112, 'eval_precision': 0.5777777777777777, 'eval_recall': 0.9285714285714286, 'eval_f1': 0.7123287671232876, 'eval_roc_auc': 0.7266483516483517, 'eval_runtime': 13.8142, 'eval_samples_per_second': 3.909, 'eval_steps_per_second': 1.013, 'epoch': 8.0}
{'loss': 0.6951, 'grad_norm': 0.4265686869621277, 'learning_rate': 1.90625e-06, 'epoch': 8.12}
{'loss': 0.6844, 'grad_norm': 1.410823941230774, 'learning_rate': 1.59375e-06, 'epoch': 8.44}
{'loss': 0.688, 'grad_norm': 0.7534577250480652, 'learning_rate': 1.28125e-06, 'epoch': 8.75}
{'eval_loss': 0.684036374092102, 'eval_accuracy': 0.6296296296296297, 'eval_precision': 0.5869565217391305, 'eval_recall': 0.9642857142857143, 'eval_f1': 0.7297297297297297, 'eval_roc_auc': 0.7307692307692308, 'eval_runtime': 13.5033, 'eval_samples_per_second': 3.999, 'eval_steps_per_second': 1.037, 'epoch': 9.0}
{'loss': 0.6887, 'grad_norm': 1.5528883934020996, 'learning_rate': 9.6875e-07, 'epoch': 9.06}
{'loss': 0.688, 'grad_norm': 0.7093526721000671, 'learning_rate': 6.562500000000001e-07, 'epoch': 9.38}
{'loss': 0.6857, 'grad_norm': 1.3813831806182861, 'learning_rate': 3.4375000000000004e-07, 'epoch': 9.69}
{'loss': 0.6859, 'grad_norm': 0.3545747697353363, 'learning_rate': 3.1250000000000005e-08, 'epoch': 10.0}
{'eval_loss': 0.6839810013771057, 'eval_accuracy': 0.6296296296296297, 'eval_precision': 0.5869565217391305, 'eval_recall': 0.9642857142857143, 'eval_f1': 0.7297297297297297, 'eval_roc_auc': 0.7321428571428572, 'eval_runtime': 13.8538, 'eval_samples_per_second': 3.898, 'eval_steps_per_second': 1.011, 'epoch': 10.0}
{'train_runtime': 1045.6763, 'train_samples_per_second': 1.205, 'train_steps_per_second': 0.306, 'train_loss': 0.6893384367227554, 'epoch': 10.0}
[CHECKPOINT] Best model @ artifacts/checkpoints/checkpoint-320
--- FINAL VALIDATION METRICS ---
accuracy  : 0.6296296296296297
precision : 0.5869565217391305
recall    : 0.9642857142857143
f1        : 0.7297297297297297
roc_auc   : 0.7321428571428572
Confusion-matrix and ROC curve saved to artifacts/plots/
[INFO] Training complete.


